{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tp1.ipynb","provenance":[],"authorship_tag":"ABX9TyMIU7yEBpcntfjA24gLCYTE"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"znHH0V_-kF3f"},"source":["import time\r\n","import re\r\n","import sys\r\n","import numpy as np\r\n","np.random.seed(2021)\r\n","\r\n","\"\"\"\r\n","\r\n","Nos comentários utilizaremos o id do usuário para definir o valor que aparece no arquivo de ratings\r\n","O índice do usuário é a linha na matriz (de ratings) que o usuário está\r\n","Raciocínio análogo para os itens\r\n","\r\n","Operações vetorizadas são muito rápidas, \r\n","porém como os dados são extremamente esparsos a computação vetorizada não foi \"\"eficiente\"\"\r\n","\r\n","Computamos os elementos usuários mais similares e armazenos em um vetor ordenado\r\n","Para facilitar a seleção dos top-k neighboors\r\n","Priority Queue(ou heapq) - binary heap - O(logn) - Worst-case Time Complexity - insertion (nlogn)\r\n","\r\n","\"\"\"\r\n","\r\n","\r\n","# TODO bbb\r\n","\r\n","# warnings.filterwarnings('ignore')\r\n","\r\n","def readFile(name_file, type=\"train\", ignore_first_line=True, users_to_add=None, items_to_add=None,\r\n","             intersect_or_union='intersect', type_return='dict'):\r\n","    \"\"\"\r\n","    Essa função lê um arquivo de usuários itens, com ou sem ratings e timestamp\r\n","    Para arquivos do tipo train é retornado um set com os usuários, um set com os itens, e um terceiro retorno\r\n","    Se type_return for 'dict' o terceiro retorno é um dicionário com chaves para usuários, e cada usuário contém\r\n","    um dicionário para seus itens e cada item indexa o rating do usuário chave para tal item\r\n","    Se type_return for 'array' o terceiro retorno é um array com pares de user,item (type == test) ou trios de\r\n","    user,item,rating (type == train)\r\n","\r\n","    Parameters\r\n","    ----------\r\n","    name_file : str\r\n","        O nome do arquivo a ser lido.\r\n","\r\n","    type : {'train', 'test'}, optional\r\n","        O tipo do arquivo a ser lido.\r\n","            Se 'train' cada linha do arquivo deve ter o formato u{user_id}:i{item_id},{rating},{timestamp}\r\n","            Se 'test' cada linha do arquivo deve ter o formato u{user_id}:i{item_id}\r\n","\r\n","    ignore_first_line : boolean, optional\r\n","        Se True ignora a primeira linha do arquivo a ser lido\r\n","\r\n","    users_to_add: set or dict, optional\r\n","        Se esse parâmetro for utilizado observe também os parâmetros items_to_add e intersect_or_union\r\n","        A saída irá conter apenas usuários em users_to_add\r\n","            Pode conter usuários que não estão em users_to_add se (items_to_add != None & intersect_or_union == 'union')\r\n","\r\n","    items_to_add: set or dict, optional\r\n","        Se esse parâmetro for utilizado observe também os parâmetros items_to_add e intersect_or_union\r\n","        A saída irá conter apenas itens em items_to_add\r\n","            Pode conter itens que não estão em items_to_add se (users_to_add != None & intersect_or_union == 'union')\r\n","\r\n","    intersect_or_union : {'intersect', 'union'}, optional\r\n","        Esse parâmetro só é utilizado quando users_to_add e items_to_add são ambos não nulos\r\n","        Se 'intersect' a saída ignora as linhas com usuários que não estão em users_to_add & ignora as linhas com itens que\r\n","            não estão em items_to_add.\r\n","        Se 'union' a saída ignora as linhas com usuários que não estão em users_to_add a menos que o item da linha\r\n","            contenha algum item em items_to_add. Ignora também as linhas com items que não estão em items_to_add a menos\r\n","            que o usuário da linha contenha algum usuário em users_to_add.\r\n","\r\n","    type_return : {'array', 'dict'}, optional\r\n","        Esse parâmetro indica se o terceiro item do retorno é um array ou um dicionário\r\n","        Se type_return for 'dict' o terceiro retorno é um dicionário com chaves para usuários, e cada usuário contém\r\n","        um dicionário para seus itens e cada item indexa o rating do usuário chave para tal item\r\n","        Se type_return for 'array' o terceiro retorno é um array com pares de user,item (type == test) ou trios de\r\n","        user,item,rating (type == train)\r\n","\r\n","    \"\"\"\r\n","\r\n","    with open(name_file, 'r') as file:\r\n","        lines = file.readlines()\r\n","\r\n","    if ignore_first_line:\r\n","        lines = lines[1:]\r\n","\r\n","    if type == \"test\":\r\n","        p = re.compile('u([0-9]*):i([0-9]*)')\r\n","    elif type == \"train\":\r\n","        p = re.compile('u([0-9]*):i([0-9]*),([0-9]*),([0-9]*)')\r\n","    else:\r\n","        raise Exception(\"Invalid type of file\")\r\n","\r\n","    all_users = set()\r\n","    all_items = set()\r\n","\r\n","    users_items_map = {}\r\n","\r\n","    cont_removed_ratings = 0\r\n","\r\n","    add_all = users_to_add is None and items_to_add is None\r\n","    add_by_items = users_to_add is None and not items_to_add is None\r\n","    add_by_users = not users_to_add is None and items_to_add is None\r\n","\r\n","    array_user_item_pairs = []\r\n","\r\n","    for line in lines:\r\n","        m = p.match(line)\r\n","\r\n","        u = int(m.groups()[0])\r\n","        i = int(m.groups()[1])\r\n","\r\n","        if type == \"test\":\r\n","            r = 0\r\n","        else:\r\n","            r = int(m.groups()[2])\r\n","\r\n","        all_users.add(u)\r\n","        all_items.add(i)\r\n","\r\n","        should_be_added = False\r\n","        if add_all:\r\n","            should_be_added = True\r\n","        elif add_by_items and add_by_users:\r\n","            if intersect_or_union == 'intersect':\r\n","                if u in users_to_add and i in items_to_add:\r\n","                    should_be_added = True\r\n","            if intersect_or_union == 'union':\r\n","                if u in users_to_add or i in items_to_add:\r\n","                    should_be_added = True\r\n","        elif add_by_users:\r\n","            if u in users_to_add:\r\n","                should_be_added = True\r\n","        elif add_by_items:\r\n","            if i in items_to_add:\r\n","                should_be_added = True\r\n","\r\n","        if should_be_added:\r\n","            if type_return == 'array' and type == 'train':\r\n","                array_user_item_pairs.append((u, i, r))\r\n","            elif type_return == 'array' and type == 'test':\r\n","                array_user_item_pairs.append((u, i))\r\n","            else:\r\n","                users_items_map.setdefault(u, {})\r\n","                users_items_map[u].setdefault(i, r)\r\n","        else:\r\n","            cont_removed_ratings += 1\r\n","\r\n","    # print(f\"{cont_removed_ratings} removed ratings\")\r\n","    if type_return == 'array':\r\n","        return all_users, all_items, array_user_item_pairs\r\n","    return all_users, all_items, users_items_map\r\n","\r\n","\r\n","\"\"\"\r\n","Lemos os arquivos de treino e teste de uma só vez para garantir que todos os usuários e itens da coleção estarão\r\n","na matriz de ratings\r\n","\r\n","TODO regularization SGD\r\n","\"\"\"\r\n","\r\n","\r\n","def indexTwoSets(first_set, second_set) -> (dict, dict):\r\n","    \"\"\"\r\n","    Retorna a indexação dos dados nos conjuntos first_set e second_set (essa indexação pode ser utilizada para acessar a\r\n","    posição de um elemento do conjunto em um vetor indexado a partir de zero\r\n","\r\n","    Parameters\r\n","    ----------\r\n","    first_set: set or dict\r\n","        É um conjunto de dados únicos\r\n","    second_set: set or dict\r\n","        É um conjunto de dados únicos\r\n","\r\n","    Returns\r\n","    -------\r\n","        indexes, not_in_first_set\r\n","        indexes:\r\n","            Junta os dados do first_set com o second_set, e para cada item única desse conjunto é assinalado um índice\r\n","        not_in_first_set: dict\r\n","            Contém as chaves que estão no second_set mas não no first_set\r\n","\r\n","    \"\"\"\r\n","\r\n","    indexes = {}\r\n","    count = 0\r\n","    for u in first_set:\r\n","        if u not in indexes:\r\n","            indexes.setdefault(u, count)\r\n","            count += 1\r\n","\r\n","    not_in_first_set = {}\r\n","    for u in second_set:\r\n","        if u not in indexes:\r\n","            indexes.setdefault(u, count)\r\n","            count += 1\r\n","            not_in_first_set.setdefault(u, 0)\r\n","\r\n","    return indexes, not_in_first_set\r\n","\r\n","\r\n","def createMatrixRatings(all_users_test, all_items_test, all_users_train, all_items_train,\r\n","                        users_itens_map_train, default_value=0) -> (dict, dict, np.array, np.array):\r\n","    \"\"\"\r\n","    Retorna a indexação de todos os usuários em all_users_test e all_users_train, assim como indexa todos os itens\r\n","    em all_items_test e all_items_train na matriz de ratings (np.array bidimensional) que também é retornada\r\n","\r\n","    Parameters\r\n","    ----------\r\n","    all_users_test: set or dict\r\n","        É um conjunto de usuários, é necessário pois não seria possível fazer uma predição para esse usuário se ele não\r\n","        estiver na matriz de ratings (mesmo que ele não tenha feito nenhum rating no traino)\r\n","    all_items_test: set or dict\r\n","        É um conjunto de itens, é necessário pois não seria possível fazer uma predição desse item para um usuário se\r\n","        ele não estiver na matriz de ratings (mesmo que ele não tenha recebido nenhum rating no traino)\r\n","    all_users_train: set or dict\r\n","        É o conjunto de usuários em users_itens_map_train\r\n","    all_items_train: set or dict\r\n","        É o conjunto de items em users_itens_map_train\r\n","    users_itens_map_train: dict\r\n","        Contém ratings de usuários para itens: As chaves iniciais são usuários, e cada usuário contém um dicionário\r\n","        para seus itens, e cada item indexa o rating do usuário chave para tal item\r\n","    default_value: float\r\n","        É o valor padrão dos ratings na matriz retornada para os pares de (usuário, item) que não tem rating\r\n","\r\n","    Returns\r\n","    -------\r\n","        indexes_users, indexes_items, ratings, bool_ratings\r\n","        indexes_users:\r\n","            É um dicionário com a união das chaves em all_users_train e all_users_test, e mapeia o índice desse usuário\r\n","            na matriz de ratings (é um índice de uma linha da matriz)\r\n","        indexes_items:\r\n","            É um dicionário com a união das chaves em all_items_train e all_items_test, e mapeia o índice desse item\r\n","            na matriz de ratings (é um índice de uma coluna da matriz)\r\n","        ratings:\r\n","            É um np.array bidimensinal onde cada linha é um usuário (de all_users_train e all_users_test)\r\n","            e cada coluna um item de (de all_items_train e all_items_test), com valor padrão definido em default_value,\r\n","            e com os valores dos ratings de users_itens_map_train\r\n","        bool_ratings:\r\n","            É um np.array bidimensinal onde cada linha é um usuário (de all_users_train e all_users_test)\r\n","            e cada coluna um item de (de all_items_train e all_items_test), com valor padrão 0,\r\n","            e onde há ratings em users_itens_map_train o valor é 1 (apenas para diferenciar um rating 0 do valor default 0)\r\n","\r\n","    \"\"\"\r\n","\r\n","    indexes_users = indexTwoSets(all_users_train, all_users_test)\r\n","    user_count = len(indexes_users)\r\n","\r\n","    indexes_items = indexTwoSets(all_items_test, all_items_train)\r\n","    item_count = len(indexes_items)\r\n","\r\n","    ratings = np.zeros((user_count, item_count), dtype=np.float) + default_value\r\n","    bool_ratings = np.zeros((user_count, item_count), dtype=np.float)\r\n","    # i_bool_ratings = np.ones((user_count, item_count), dtype=np.float)\r\n","\r\n","    for u in users_itens_map_train:\r\n","        for i in users_itens_map_train[u]:\r\n","            ratings[indexes_users[u]][indexes_items[i]] = users_itens_map_train[u][i]\r\n","            bool_ratings[indexes_users[u]][indexes_items[i]] = 1\r\n","            # i_bool_ratings[indexes_users[u]][indexes_items[i]] = 0\r\n","\r\n","    return indexes_users, indexes_items, ratings, bool_ratings\r\n","\r\n","\r\n","def computMeanCenteringNormalization(ratings, bool_ratings):\r\n","    \"\"\"\r\n","\r\n","    Parameters\r\n","    ----------\r\n","    ratings: np.array\r\n","        Matriz de ratings (cada linha é um usuário e cada coluna um item)\r\n","    bool_ratings: np.array\r\n","        Matriz boolean de ratings (cada linha é um usuário e cada coluna um item),\r\n","        É utilizada para diferenciar um rating 0 de um valor 0 na matriz que é a ausência de rating\r\n","    Returns\r\n","    -------\r\n","        Retorna uma matriz do mesmo tamanho das matriz de entrada, após fazer o cálculo da normalização central de rating\r\n","    \"\"\"\r\n","    users_mean_rating = np.sum(ratings, axis=1) / np.sum(bool_ratings, axis=1)\r\n","    np.nan_to_num(users_mean_rating, copy=False)\r\n","    num_items = ratings.shape[1]\r\n","    return ratings - np.multiply(bool_ratings, np.tile(users_mean_rating, (num_items, 1)).T)\r\n","\r\n","\r\n","def computeCosineSimilarity(user_index, ratings):\r\n","    \"\"\"\r\n","\r\n","    Parameters\r\n","    ----------\r\n","    user_index: int\r\n","        Índice do usuário na matriz de ratings para o qual queremos calcular a similaridade com os demais usuários da matriz\r\n","    ratings: np.array\r\n","        Matriz de ratings (cada linha é um usuário e cada coluna um item)\r\n","\r\n","    Returns\r\n","    -------\r\n","        Retorna um np.array com tamanho igual ao número de linhas da matriz de ratings, onde cada valor desse vetor é\r\n","        a similaridade do cosseno usuário dessa linha na matriz com o usuário do índice passado em user_index\r\n","    \"\"\"\r\n","    all_similarities = np.sum(ratings[user_index] * ratings, axis=1) / (np.sqrt(np.sum(\r\n","        ratings[user_index] * ratings[user_index])) * np.sqrt(np.sum(np.multiply(ratings, ratings), axis=1)))\r\n","    return all_similarities\r\n","\r\n","\r\n","class SGD:\r\n","    \"\"\"\r\n","\r\n","    \"\"\"\r\n","\r\n","    def __init__(self, alpha=0.001, num_iteracoes=50, num_latent_factor=5, lambda_reg=0):\r\n","        \"\"\"\r\n","\r\n","        Parameters\r\n","        ----------\r\n","        alpha: float Taxa de aprendizado do SGD\r\n","        num_iteracoes: int Quantidade de iterações performadas (cada iteração ajusta cada um dos ratings em users_items_map_train\r\n","        num_latent_factor: int número de fatores latentes que serão estimados\r\n","        lambda_reg: float regularaização do erro - to avoid overfitting\r\n","        \"\"\"\r\n","        self.alpha = alpha\r\n","        self.lambda_reg = lambda_reg\r\n","        self.num_iteracoes = num_iteracoes\r\n","        self.num_latent_factor = num_latent_factor\r\n","        self.P = []\r\n","        self.Q = []\r\n","\r\n","    def fit(self, users_items_map_train, indexes_users, indexes_items):\r\n","        \"\"\"\r\n","\r\n","        Parameters\r\n","        ----------\r\n","        users_items_map_train: dict of dicts dicionário de usuários, onde cada usuário tem um dicionário de itens mapeando\r\n","            o rating desse usuário para esse item\r\n","        indexes_users: dict Dicionário com todos os usuários que serão utilizados para construir as matrizes de fatores\r\n","            latentes (pode conter users not in users_items_map_train)\r\n","        indexes_items: dict Dicionário com todos os itens que serão utilizados para construir as matrizes de fatores\r\n","            latentes (pode conter items not in users_items_map_train)\r\n","\r\n","        Returns\r\n","        -------\r\n","        Retorna as matrizes P e Q que são representações aproximadas da matriz de ratings\r\n","\r\n","        \"\"\"\r\n","        num_users = len(indexes_users)\r\n","        num_items = len(indexes_items)\r\n","\r\n","        self.P = np.ones((num_users, self.num_latent_factor), dtype=np.float)\r\n","        self.Q = np.ones((self.num_latent_factor, num_items), dtype=np.float)\r\n","\r\n","        user_keys = np.array(list(users_items_map_train.keys()))\r\n","\r\n","        for iter in range(self.num_iteracoes):\r\n","            np.random.shuffle(user_keys)\r\n","            for u in user_keys:\r\n","                # for u in users_items_map_train:\r\n","                for i in users_items_map_train[u]:\r\n","                    eui = users_items_map_train[u][i] - np.sum(\r\n","                        (self.P[indexes_users[u]]) * (self.Q[:, indexes_items[i]]))\r\n","\r\n","                    # P[indexes_users[u]] = P[indexes_users[u]] + 2 * alpha * eui * Q[:, indexes_items[i]]\r\n","                    # Q[:, indexes_items[i]] = Q[:, indexes_items[i]] + 2 * alpha * eui * P[indexes_users[u]]\r\n","\r\n","                    rP = self.P[indexes_users[u]] + 2 * self.alpha * eui * self.Q[:,indexes_items[i]] - 2 * self.alpha * self.lambda_reg * \\\r\n","                         self.P[indexes_users[u]]\r\n","\r\n","                    stop = False\r\n","                    if np.isnan(rP).any():\r\n","                        stop = True\r\n","\r\n","                    rQ = self.Q[:, indexes_items[i]] + 2 * self.alpha * eui * rP - 2 * self.alpha * self.lambda_reg * \\\r\n","                         - 2 * self.alpha * self.lambda_reg * self.Q[:,indexes_items[i]]\r\n","\r\n","                    if np.isnan(rQ).any():\r\n","                        stop = True\r\n","\r\n","                    # O método pode divergir para valores muito grandes de alpha\r\n","                    if not stop:\r\n","                        self.P[indexes_users[u]] = rP\r\n","                        self.Q[:, indexes_items[i]] = rQ\r\n","                    else:\r\n","                        return self.P, self.Q\r\n","        return self.P, self.Q\r\n","\r\n","    def predict(self, users_itens, indexes_users, indexes_items, users_without_rating=None,\r\n","                type_of_predict_for_users_without_rating='default'):\r\n","        \"\"\"\r\n","\r\n","        Parameters\r\n","        ----------\r\n","        users_itens: array of (u, i) para ser computado o rating do user u para o item i\r\n","        indexes_users: dict Dicionário com todos os usuários que serão utilizados para construir as matrizes de fatores\r\n","            latentes (pode conter users not in users_items_map_train) - contém os índices dos usuários na matriz de fator latente\r\n","        indexes_items: dict Dicionário com todos os itens que serão utilizados para construir as matrizes de fatores\r\n","            latentes (pode conter items not in users_items_map_train) - contém os índices dos itens na matriz de fator latente\r\n","        users_without_rating: dict Dicionário com todos os usuários que não possuem ratings no conjunto de treino (fit function)\r\n","            Para esses usuários o rating para um item i pode ser a média de ratings desse item i, a média global de ratings,\r\n","            ou o valor da decomposição SGD - que é especificado no parâmetro type_of_predict_for_users_without_rating\r\n","        type_of_predict_for_users_without_rating: {'mean_item', 'global_mean', 'default'}, optional\r\n","            mean_item - Para usuários do conjunto users_without_rating o rating computado para um item i é a média dos ratings do item i\r\n","            global_mean - Para usuários do conjunto users_without_rating o rating computado para um item i é a média global dos ratings\r\n","            default - Utiliza a decomposição do SGD para gerar todos os ratings\r\n","        Returns\r\n","        -------\r\n","             Retorna um array de ratings para cada par (u, i) em users_itens\r\n","        \"\"\"\r\n","\r\n","        if not users_without_rating is None:\r\n","            print(\"inside\")\r\n","            result = np.matmul(self.P, self.Q)\r\n","            mean_item = np.mean(result, axis=0)\r\n","            global_mean = np.mean(mean_item)\r\n","        else:\r\n","            users_without_rating = {}\r\n","            result = None\r\n","\r\n","        predicts = np.zeros(len(users_itens), dtype=np.float)\r\n","        cont = 0\r\n","\r\n","        if users_without_rating is None:\r\n","            users_without_rating = {}\r\n","\r\n","        # for (u, i) in users_itens:\r\n","        for (u, i, r) in users_itens:\r\n","            if u in users_without_rating:\r\n","                if type_of_predict_for_users_without_rating == 'mean_item':\r\n","                    predicts[cont] = mean_item[indexes_items[i]]\r\n","                elif type_of_predict_for_users_without_rating == 'global_mean':\r\n","                    predicts[cont] = global_mean\r\n","                else:\r\n","                    predicts[cont] = result[indexes_users[u]][indexes_items[i]]\r\n","                #\r\n","            else:\r\n","                if result is None:\r\n","                    predicts[cont] = np.matmul(self.P[indexes_users[u]], self.Q[:, indexes_items[i]])\r\n","                else:\r\n","                    predicts[cont] = result[indexes_users[u]][indexes_items[i]]\r\n","            cont += 1\r\n","        return predicts\r\n","\r\n","\r\n","def writePredict(name_file_output, users_itens, predicts, header=\"UserId:ItemId,Prediction\", verbose=False):\r\n","    \"\"\"\r\n","\r\n","    Parameters\r\n","    ----------\r\n","    name_file_output: str Nome do arquivo de saída\r\n","    users_itens: array de pares (u, i)\r\n","    predicts: array de ratings preditos para todos os pares (u, i)\r\n","    header: str Cabeçalho do arquivo de saída\r\n","    verbose: bool Escreve as predições na saída padrão\r\n","\r\n","    Returns\r\n","    -------\r\n","\r\n","    \"\"\"\r\n","    if verbose:\r\n","        for u_i, p in zip(users_itens, predicts):\r\n","            u = u_i[0]\r\n","            i = u_i[1]\r\n","            print(\"u\" + str(u).zfill(7) + \":\" + \"i\" + str(i).zfill(7) + \",\" + str(p))\r\n","    else:\r\n","        with open(name_file_output, 'w') as file:\r\n","            file.write(header + \"\\n\")\r\n","            for u_i, p in zip(users_itens, predicts):\r\n","                u = u_i[0]\r\n","                i = u_i[1]\r\n","                file.write(\"u\" + str(u).zfill(7) + \":\" + \"i\" + str(i).zfill(7) + \",\" + str(p) + \"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ze8AdZ-Lkn99"},"source":["import random\r\n","import numpy as np\r\n","import os\r\n","os.mkdir('fold')\r\n","u, i, u_i_r = readFile(\"ratings.csv\", type=\"train\", type_return=\"array\")\r\n","\r\n","size_pop = len(u_i_r)\r\n","size_pop10 = int(0.1 * len(u_i_r))\r\n","\r\n","for f in range(5):\r\n","    r = random.sample(range(size_pop), size_pop10)\r\n","    r = np.sort(r)\r\n","\r\n","    cp = 0\r\n","    cs10 = 0\r\n","    with open(f\"fold/ratings-{f}.csv\", 'w') as fp:\r\n","        with open(f\"fold/targets-{f}.csv\", 'w') as fs10:\r\n","            fp.write(\"bl\\n\")\r\n","            fs10.write(\"bl\\n\")\r\n","            for i in range(size_pop):\r\n","                if cs10 < size_pop10:\r\n","                    if r[cs10] == i:\r\n","                        fs10.write(\"u\" + str(u_i_r[i][0]).zfill(7) + \":\" + \"i\" + str(u_i_r[i][1]).zfill(7) + \",\" + str(\r\n","                            u_i_r[i][2]) + \",1421526527\" + \"\\n\")\r\n","                        cs10 += 1\r\n","                    else:\r\n","                        fp.write(\"u\" + str(u_i_r[i][0]).zfill(7) + \":\" + \"i\" + str(u_i_r[i][1]).zfill(7) + \",\" + str(\r\n","                            u_i_r[i][2]) + \",1421526527\" + \"\\n\")\r\n","\r\n","                        cp += 1\r\n","                else:\r\n","                    fp.write(\"u\" + str(u_i_r[i][0]).zfill(7) + \":\" + \"i\" + str(u_i_r[i][1]).zfill(7) + \",\" + str(\r\n","                        u_i_r[i][2]) + \",1421526527\" + \"\\n\")\r\n","\r\n","                    cp += 1\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iL8yriwYu-I_","executionInfo":{"status":"ok","timestamp":1611628789803,"user_tz":180,"elapsed":13053688,"user":{"displayName":"Pedro Henrique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBTPHdXq55BqU30ZQ23IGjf75MSq79U70jv4g-aw=s64","userId":"14617956053752650928"}},"outputId":"043254d3-bc70-4fed-930a-3b42d4127205"},"source":["start = time.time()\r\n","\r\n","# all_users_predict, all_items_predict, users_items_array_to_predict = readFile(sys.argv[2], type=\"test\",\r\n","#                                                                               type_return=\"array\")\r\n","# all_users_train, all_items_train, users_items_map_train = readFile(sys.argv[1], type=\"train\")\r\n","\r\n","##################\r\n","all_users_predict, all_items_predict, users_items_array_to_predict = readFile(\"fold/targets-3.csv\", type=\"train\",\r\n","                                                                                type_return=\"array\")\r\n","all_users_train, all_items_train, users_items_map_train = readFile(\"fold/ratings-3.csv\", type=\"train\")\r\n","\r\n","y_true = []\r\n","for i in range(len(users_items_array_to_predict)):\r\n","    y_true.append(users_items_array_to_predict[i][2])\r\n","y_true = np.array(y_true)\r\n","###################3\r\n","\r\n","# indexes_users, indexes_items, ratings, bool_ratings = createMatrixRatings(all_users_predict,\r\n","#                                                                           all_items_predict,\r\n","#                                                                           all_users_train,\r\n","#                                                                           all_items_train,\r\n","#                                                                           users_items_map_train)\r\n","# ratings = computMeanCenteringNormalization(ratings, bool_ratings)\r\n","\r\n","# similarities = []\r\n","# for user in all_users_test:\r\n","#     similarities.append(computeSimilarity(indexes_users[user], m))\r\n","#     break\r\n","\r\n","indexes_users, users_without_rating = indexTwoSets(all_users_train, all_users_predict)\r\n","indexes_items, _ = indexTwoSets(all_items_predict, all_items_train)\r\n","\r\n","\r\n","#grão fino de num_latent_factor=5 de alpha=0.001 e de lambda_reg=0.005 (vou variar o lambda_reg mas num grão maior só pq errei na imp anterior\r\n","#tentar um batch SGD\r\n","best = 999999999\r\n","bests = []\r\n","num_latent_factor_arr = {}\r\n","lambda_reg_arr = {}\r\n","alpha_arr = {}\r\n","\r\n","for alpha in [0.0007, 0.001, 0.003]:\r\n","    for lambda_reg in [0, 0.0007, 0.001, 0.003]:\r\n","        for num_latent_factor in [2, 3, 4, 8]:\r\n","\r\n","            if alpha not in alpha_arr:\r\n","                alpha_arr.setdefault(alpha, [])\r\n","            if lambda_reg not in lambda_reg_arr:\r\n","                lambda_reg_arr.setdefault(lambda_reg, [])\r\n","            if num_latent_factor not in num_latent_factor_arr:\r\n","                num_latent_factor_arr.setdefault(num_latent_factor, [])\r\n","\r\n","            start = time.time()\r\n","            model = SGD(num_iteracoes=30, num_latent_factor=num_latent_factor, alpha=alpha, lambda_reg=lambda_reg)\r\n","            # model = SGD(num_iteracoes=5, num_latent_factor=5, alpha=0.001, lambda_reg=0)\r\n","            model.fit(users_items_map_train, indexes_users, indexes_items)\r\n","\r\n","            predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items)\r\n","\r\n","            predicts = np.array(predicts)  ###################\r\n","            rmse = np.nan_to_num(np.sqrt(np.mean((y_true - predicts) ** 2)))  ############\r\n","            print(f\"{alpha}, {lambda_reg}, {num_latent_factor}, rmse: {rmse}\")############\r\n","\r\n","            # writePredict(\"results.csv\", users_items_array_to_predict, predicts, verbose=False)\r\n","\r\n","            end = time.time()\r\n","\r\n","            alpha_arr[alpha].append(rmse)\r\n","            lambda_reg_arr[lambda_reg].append(rmse)\r\n","            num_latent_factor_arr[num_latent_factor].append(rmse)\r\n","            print(\"Elapsed Time: %.2fs\" % (end - start))\r\n","            if rmse < best:\r\n","                best = rmse\r\n","                bests = []\r\n","                bests.append(alpha)\r\n","                bests.append(lambda_reg)\r\n","                bests.append(num_latent_factor)\r\n","                print(\"NEW BEST\")\r\n","            print(\"-------------------------------\")\r\n","print(bests)\r\n","\r\n","print(\"**************************\")\r\n","print(alpha_arr)\r\n","print(\"**************************\")\r\n","print(lambda_reg_arr)\r\n","print(\"**************************\")\r\n","print(num_latent_factor_arr)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.0007, 0, 2, rmse: 1.8962629124977626\n","Elapsed Time: 270.10s\n","NEW BEST\n","-------------------------------\n","0.0007, 0, 3, rmse: 1.7239882029844498\n","Elapsed Time: 271.88s\n","NEW BEST\n","-------------------------------\n","0.0007, 0, 4, rmse: 1.6089779539576528\n","Elapsed Time: 270.75s\n","NEW BEST\n","-------------------------------\n","0.0007, 0, 8, rmse: 1.4681648514608552\n","Elapsed Time: 273.80s\n","NEW BEST\n","-------------------------------\n","0.0007, 0.0007, 2, rmse: 1.896480486783705\n","Elapsed Time: 271.76s\n","-------------------------------\n","0.0007, 0.0007, 3, rmse: 1.7243868541167449\n","Elapsed Time: 271.58s\n","-------------------------------\n","0.0007, 0.0007, 4, rmse: 1.6092665684873428\n","Elapsed Time: 272.29s\n","-------------------------------\n","0.0007, 0.0007, 8, rmse: 1.4682749740849188\n","Elapsed Time: 273.07s\n","-------------------------------\n","0.0007, 0.001, 2, rmse: 1.896256178668206\n","Elapsed Time: 269.67s\n","-------------------------------\n","0.0007, 0.001, 3, rmse: 1.7239275780422287\n","Elapsed Time: 270.54s\n","-------------------------------\n","0.0007, 0.001, 4, rmse: 1.6091976907844414\n","Elapsed Time: 272.47s\n","-------------------------------\n","0.0007, 0.001, 8, rmse: 1.4679255368627417\n","Elapsed Time: 272.03s\n","NEW BEST\n","-------------------------------\n","0.0007, 0.003, 2, rmse: 1.8959803400411601\n","Elapsed Time: 271.03s\n","-------------------------------\n","0.0007, 0.003, 3, rmse: 1.723826288076145\n","Elapsed Time: 272.28s\n","-------------------------------\n","0.0007, 0.003, 4, rmse: 1.608975335941946\n","Elapsed Time: 273.82s\n","-------------------------------\n","0.0007, 0.003, 8, rmse: 1.468930418778976\n","Elapsed Time: 273.45s\n","-------------------------------\n","0.001, 0, 2, rmse: 1.850202494981479\n","Elapsed Time: 270.90s\n","-------------------------------\n","0.001, 0, 3, rmse: 1.6973675066418445\n","Elapsed Time: 272.61s\n","-------------------------------\n","0.001, 0, 4, rmse: 1.595436754372912\n","Elapsed Time: 274.70s\n","-------------------------------\n","0.001, 0, 8, rmse: 1.4700986738837654\n","Elapsed Time: 271.49s\n","-------------------------------\n","0.001, 0.0007, 2, rmse: 1.8505385473472078\n","Elapsed Time: 269.93s\n","-------------------------------\n","0.001, 0.0007, 3, rmse: 1.6972962666544136\n","Elapsed Time: 270.75s\n","-------------------------------\n","0.001, 0.0007, 4, rmse: 1.5962447933024317\n","Elapsed Time: 271.90s\n","-------------------------------\n","0.001, 0.0007, 8, rmse: 1.4700810001217552\n","Elapsed Time: 271.95s\n","-------------------------------\n","0.001, 0.001, 2, rmse: 1.8506694703450683\n","Elapsed Time: 270.54s\n","-------------------------------\n","0.001, 0.001, 3, rmse: 1.6976147903436911\n","Elapsed Time: 270.92s\n","-------------------------------\n","0.001, 0.001, 4, rmse: 1.5961544800750154\n","Elapsed Time: 271.64s\n","-------------------------------\n","0.001, 0.001, 8, rmse: 1.472021334470938\n","Elapsed Time: 272.12s\n","-------------------------------\n","0.001, 0.003, 2, rmse: 1.850919706609337\n","Elapsed Time: 271.21s\n","-------------------------------\n","0.001, 0.003, 3, rmse: 1.6973601392634514\n","Elapsed Time: 270.51s\n","-------------------------------\n","0.001, 0.003, 4, rmse: 1.5958352455077027\n","Elapsed Time: 271.43s\n","-------------------------------\n","0.001, 0.003, 8, rmse: 1.4700194036212053\n","Elapsed Time: 273.21s\n","-------------------------------\n","0.003, 0, 2, rmse: 1.8005364250011835\n","Elapsed Time: 269.13s\n","-------------------------------\n","0.003, 0, 3, rmse: 1.6773807149581863\n","Elapsed Time: 272.42s\n","-------------------------------\n","0.003, 0, 4, rmse: 1.60014852941341\n","Elapsed Time: 272.74s\n","-------------------------------\n","0.003, 0, 8, rmse: 1.5025550599673736\n","Elapsed Time: 274.67s\n","-------------------------------\n","0.003, 0.0007, 2, rmse: 1.8001742035508146\n","Elapsed Time: 272.26s\n","-------------------------------\n","0.003, 0.0007, 3, rmse: 1.6775618514316089\n","Elapsed Time: 270.68s\n","-------------------------------\n","0.003, 0.0007, 4, rmse: 1.5986150593305195\n","Elapsed Time: 271.63s\n","-------------------------------\n","0.003, 0.0007, 8, rmse: 1.5039375399695205\n","Elapsed Time: 273.14s\n","-------------------------------\n","0.003, 0.001, 2, rmse: 1.8007124482735408\n","Elapsed Time: 271.53s\n","-------------------------------\n","0.003, 0.001, 3, rmse: 1.6782787464453222\n","Elapsed Time: 271.48s\n","-------------------------------\n","0.003, 0.001, 4, rmse: 1.599383160456623\n","Elapsed Time: 272.79s\n","-------------------------------\n","0.003, 0.001, 8, rmse: 1.5026751528360311\n","Elapsed Time: 274.22s\n","-------------------------------\n","0.003, 0.003, 2, rmse: 1.7988711982144054\n","Elapsed Time: 271.70s\n","-------------------------------\n","0.003, 0.003, 3, rmse: 1.6792336569678512\n","Elapsed Time: 272.42s\n","-------------------------------\n","0.003, 0.003, 4, rmse: 1.6011629333731188\n","Elapsed Time: 272.53s\n","-------------------------------\n","0.003, 0.003, 8, rmse: 1.5032627131200094\n","Elapsed Time: 271.36s\n","-------------------------------\n","[0.0007, 0.001, 8]\n","**************************\n","{0.0007: [1.8962629124977626, 1.7239882029844498, 1.6089779539576528, 1.4681648514608552, 1.896480486783705, 1.7243868541167449, 1.6092665684873428, 1.4682749740849188, 1.896256178668206, 1.7239275780422287, 1.6091976907844414, 1.4679255368627417, 1.8959803400411601, 1.723826288076145, 1.608975335941946, 1.468930418778976], 0.001: [1.850202494981479, 1.6973675066418445, 1.595436754372912, 1.4700986738837654, 1.8505385473472078, 1.6972962666544136, 1.5962447933024317, 1.4700810001217552, 1.8506694703450683, 1.6976147903436911, 1.5961544800750154, 1.472021334470938, 1.850919706609337, 1.6973601392634514, 1.5958352455077027, 1.4700194036212053], 0.003: [1.8005364250011835, 1.6773807149581863, 1.60014852941341, 1.5025550599673736, 1.8001742035508146, 1.6775618514316089, 1.5986150593305195, 1.5039375399695205, 1.8007124482735408, 1.6782787464453222, 1.599383160456623, 1.5026751528360311, 1.7988711982144054, 1.6792336569678512, 1.6011629333731188, 1.5032627131200094]}\n","**************************\n","{0: [1.8962629124977626, 1.7239882029844498, 1.6089779539576528, 1.4681648514608552, 1.850202494981479, 1.6973675066418445, 1.595436754372912, 1.4700986738837654, 1.8005364250011835, 1.6773807149581863, 1.60014852941341, 1.5025550599673736], 0.0007: [1.896480486783705, 1.7243868541167449, 1.6092665684873428, 1.4682749740849188, 1.8505385473472078, 1.6972962666544136, 1.5962447933024317, 1.4700810001217552, 1.8001742035508146, 1.6775618514316089, 1.5986150593305195, 1.5039375399695205], 0.001: [1.896256178668206, 1.7239275780422287, 1.6091976907844414, 1.4679255368627417, 1.8506694703450683, 1.6976147903436911, 1.5961544800750154, 1.472021334470938, 1.8007124482735408, 1.6782787464453222, 1.599383160456623, 1.5026751528360311], 0.003: [1.8959803400411601, 1.723826288076145, 1.608975335941946, 1.468930418778976, 1.850919706609337, 1.6973601392634514, 1.5958352455077027, 1.4700194036212053, 1.7988711982144054, 1.6792336569678512, 1.6011629333731188, 1.5032627131200094]}\n","**************************\n","{2: [1.8962629124977626, 1.896480486783705, 1.896256178668206, 1.8959803400411601, 1.850202494981479, 1.8505385473472078, 1.8506694703450683, 1.850919706609337, 1.8005364250011835, 1.8001742035508146, 1.8007124482735408, 1.7988711982144054], 3: [1.7239882029844498, 1.7243868541167449, 1.7239275780422287, 1.723826288076145, 1.6973675066418445, 1.6972962666544136, 1.6976147903436911, 1.6973601392634514, 1.6773807149581863, 1.6775618514316089, 1.6782787464453222, 1.6792336569678512], 4: [1.6089779539576528, 1.6092665684873428, 1.6091976907844414, 1.608975335941946, 1.595436754372912, 1.5962447933024317, 1.5961544800750154, 1.5958352455077027, 1.60014852941341, 1.5986150593305195, 1.599383160456623, 1.6011629333731188], 8: [1.4681648514608552, 1.4682749740849188, 1.4679255368627417, 1.468930418778976, 1.4700986738837654, 1.4700810001217552, 1.472021334470938, 1.4700194036212053, 1.5025550599673736, 1.5039375399695205, 1.5026751528360311, 1.5032627131200094]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BznNnPDSu-ME","executionInfo":{"status":"ok","timestamp":1611799603369,"user_tz":180,"elapsed":721,"user":{"displayName":"Pedro Henrique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBTPHdXq55BqU30ZQ23IGjf75MSq79U70jv4g-aw=s64","userId":"14617956053752650928"}}},"source":["# r= {0.0007: [1.8962629124977626, 1.7239882029844498, 1.6089779539576528, 1.4681648514608552, 1.896480486783705, 1.7243868541167449, 1.6092665684873428, 1.4682749740849188, 1.896256178668206, 1.7239275780422287, 1.6091976907844414, 1.4679255368627417, 1.8959803400411601, 1.723826288076145, 1.608975335941946, 1.468930418778976], 0.001: [1.850202494981479, 1.6973675066418445, 1.595436754372912, 1.4700986738837654, 1.8505385473472078, 1.6972962666544136, 1.5962447933024317, 1.4700810001217552, 1.8506694703450683, 1.6976147903436911, 1.5961544800750154, 1.472021334470938, 1.850919706609337, 1.6973601392634514, 1.5958352455077027, 1.4700194036212053], 0.003: [1.8005364250011835, 1.6773807149581863, 1.60014852941341, 1.5025550599673736, 1.8001742035508146, 1.6775618514316089, 1.5986150593305195, 1.5039375399695205, 1.8007124482735408, 1.6782787464453222, 1.599383160456623, 1.5026751528360311, 1.7988711982144054, 1.6792336569678512, 1.6011629333731188, 1.5032627131200094]}\r\n","# r={0: [1.8962629124977626, 1.7239882029844498, 1.6089779539576528, 1.4681648514608552, 1.850202494981479, 1.6973675066418445, 1.595436754372912, 1.4700986738837654, 1.8005364250011835, 1.6773807149581863, 1.60014852941341, 1.5025550599673736], 0.0007: [1.896480486783705, 1.7243868541167449, 1.6092665684873428, 1.4682749740849188, 1.8505385473472078, 1.6972962666544136, 1.5962447933024317, 1.4700810001217552, 1.8001742035508146, 1.6775618514316089, 1.5986150593305195, 1.5039375399695205], 0.001: [1.896256178668206, 1.7239275780422287, 1.6091976907844414, 1.4679255368627417, 1.8506694703450683, 1.6976147903436911, 1.5961544800750154, 1.472021334470938, 1.8007124482735408, 1.6782787464453222, 1.599383160456623, 1.5026751528360311], 0.003: [1.8959803400411601, 1.723826288076145, 1.608975335941946, 1.468930418778976, 1.850919706609337, 1.6973601392634514, 1.5958352455077027, 1.4700194036212053, 1.7988711982144054, 1.6792336569678512, 1.6011629333731188, 1.5032627131200094]}\r\n","r = {2: [1.8962629124977626, 1.896480486783705, 1.896256178668206, 1.8959803400411601, 1.850202494981479, 1.8505385473472078, 1.8506694703450683, 1.850919706609337, 1.8005364250011835, 1.8001742035508146, 1.8007124482735408, 1.7988711982144054], 3: [1.7239882029844498, 1.7243868541167449, 1.7239275780422287, 1.723826288076145, 1.6973675066418445, 1.6972962666544136, 1.6976147903436911, 1.6973601392634514, 1.6773807149581863, 1.6775618514316089, 1.6782787464453222, 1.6792336569678512], 4: [1.6089779539576528, 1.6092665684873428, 1.6091976907844414, 1.608975335941946, 1.595436754372912, 1.5962447933024317, 1.5961544800750154, 1.5958352455077027, 1.60014852941341, 1.5986150593305195, 1.599383160456623, 1.6011629333731188], 8: [1.4681648514608552, 1.4682749740849188, 1.4679255368627417, 1.468930418778976, 1.4700986738837654, 1.4700810001217552, 1.472021334470938, 1.4700194036212053, 1.5025550599673736, 1.5039375399695205, 1.5026751528360311, 1.5032627131200094]}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCOnkLyUuggf","executionInfo":{"status":"ok","timestamp":1611799605257,"user_tz":180,"elapsed":739,"user":{"displayName":"Pedro Henrique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBTPHdXq55BqU30ZQ23IGjf75MSq79U70jv4g-aw=s64","userId":"14617956053752650928"}}},"source":["# r= {0.0007: [1.8962629124977626, 1.7239882029844498, 1.6089779539576528, 1.4681648514608552, 1.896480486783705, 1.7243868541167449, 1.6092665684873428, 1.4682749740849188, 1.896256178668206, 1.7239275780422287, 1.6091976907844414, 1.4679255368627417, 1.8959803400411601, 1.723826288076145, 1.608975335941946, 1.468930418778976], 0.001: [1.850202494981479, 1.6973675066418445, 1.595436754372912, 1.4700986738837654, 1.8505385473472078, 1.6972962666544136, 1.5962447933024317, 1.4700810001217552, 1.8506694703450683, 1.6976147903436911, 1.5961544800750154, 1.472021334470938, 1.850919706609337, 1.6973601392634514, 1.5958352455077027, 1.4700194036212053], 0.003: [1.8005364250011835, 1.6773807149581863, 1.60014852941341, 1.5025550599673736, 1.8001742035508146, 1.6775618514316089, 1.5986150593305195, 1.5039375399695205, 1.8007124482735408, 1.6782787464453222, 1.599383160456623, 1.5026751528360311, 1.7988711982144054, 1.6792336569678512, 1.6011629333731188, 1.5032627131200094]}\r\n","# r={0: [1.8962629124977626, 1.7239882029844498, 1.6089779539576528, 1.4681648514608552, 1.850202494981479, 1.6973675066418445, 1.595436754372912, 1.4700986738837654, 1.8005364250011835, 1.6773807149581863, 1.60014852941341, 1.5025550599673736], 0.0007: [1.896480486783705, 1.7243868541167449, 1.6092665684873428, 1.4682749740849188, 1.8505385473472078, 1.6972962666544136, 1.5962447933024317, 1.4700810001217552, 1.8001742035508146, 1.6775618514316089, 1.5986150593305195, 1.5039375399695205], 0.001: [1.896256178668206, 1.7239275780422287, 1.6091976907844414, 1.4679255368627417, 1.8506694703450683, 1.6976147903436911, 1.5961544800750154, 1.472021334470938, 1.8007124482735408, 1.6782787464453222, 1.599383160456623, 1.5026751528360311], 0.003: [1.8959803400411601, 1.723826288076145, 1.608975335941946, 1.468930418778976, 1.850919706609337, 1.6973601392634514, 1.5958352455077027, 1.4700194036212053, 1.7988711982144054, 1.6792336569678512, 1.6011629333731188, 1.5032627131200094]}\r\n","r = {2: [1.8962629124977626, 1.896480486783705, 1.896256178668206, 1.8959803400411601, 1.850202494981479, 1.8505385473472078, 1.8506694703450683, 1.850919706609337, 1.8005364250011835, 1.8001742035508146, 1.8007124482735408, 1.7988711982144054], 3: [1.7239882029844498, 1.7243868541167449, 1.7239275780422287, 1.723826288076145, 1.6973675066418445, 1.6972962666544136, 1.6976147903436911, 1.6973601392634514, 1.6773807149581863, 1.6775618514316089, 1.6782787464453222, 1.6792336569678512], 4: [1.6089779539576528, 1.6092665684873428, 1.6091976907844414, 1.608975335941946, 1.595436754372912, 1.5962447933024317, 1.5961544800750154, 1.5958352455077027, 1.60014852941341, 1.5986150593305195, 1.599383160456623, 1.6011629333731188], 8: [1.4681648514608552, 1.4682749740849188, 1.4679255368627417, 1.468930418778976, 1.4700986738837654, 1.4700810001217552, 1.472021334470938, 1.4700194036212053, 1.5025550599673736, 1.5039375399695205, 1.5026751528360311, 1.5032627131200094]}\r\n","us = []\r\n","lu = []\r\n","for i in r:\r\n","    u = []\r\n","    for j in r[i]:\r\n","        u.append(j)\r\n","    us.append(u)\r\n","    lu.append(i)\r\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQiaH3r_u-RE","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1611799714546,"user_tz":180,"elapsed":1112,"user":{"displayName":"Pedro Henrique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBTPHdXq55BqU30ZQ23IGjf75MSq79U70jv4g-aw=s64","userId":"14617956053752650928"}},"outputId":"35a39628-3cb6-4d43-b128-b3d756190e90"},"source":["import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","\r\n","\r\n","# r= {0.0007: [1.8962629124977626, 1.7239882029844498, 1.6089779539576528, 1.4681648514608552, 1.896480486783705, 1.7243868541167449, 1.6092665684873428, 1.4682749740849188, 1.896256178668206, 1.7239275780422287, 1.6091976907844414, 1.4679255368627417, 1.8959803400411601, 1.723826288076145, 1.608975335941946, 1.468930418778976], 0.001: [1.850202494981479, 1.6973675066418445, 1.595436754372912, 1.4700986738837654, 1.8505385473472078, 1.6972962666544136, 1.5962447933024317, 1.4700810001217552, 1.8506694703450683, 1.6976147903436911, 1.5961544800750154, 1.472021334470938, 1.850919706609337, 1.6973601392634514, 1.5958352455077027, 1.4700194036212053], 0.003: [1.8005364250011835, 1.6773807149581863, 1.60014852941341, 1.5025550599673736, 1.8001742035508146, 1.6775618514316089, 1.5986150593305195, 1.5039375399695205, 1.8007124482735408, 1.6782787464453222, 1.599383160456623, 1.5026751528360311, 1.7988711982144054, 1.6792336569678512, 1.6011629333731188, 1.5032627131200094]}\r\n","# r={0: [1.8962629124977626, 1.7239882029844498, 1.6089779539576528, 1.4681648514608552, 1.850202494981479, 1.6973675066418445, 1.595436754372912, 1.4700986738837654, 1.8005364250011835, 1.6773807149581863, 1.60014852941341, 1.5025550599673736], 0.0007: [1.896480486783705, 1.7243868541167449, 1.6092665684873428, 1.4682749740849188, 1.8505385473472078, 1.6972962666544136, 1.5962447933024317, 1.4700810001217552, 1.8001742035508146, 1.6775618514316089, 1.5986150593305195, 1.5039375399695205], 0.001: [1.896256178668206, 1.7239275780422287, 1.6091976907844414, 1.4679255368627417, 1.8506694703450683, 1.6976147903436911, 1.5961544800750154, 1.472021334470938, 1.8007124482735408, 1.6782787464453222, 1.599383160456623, 1.5026751528360311], 0.003: [1.8959803400411601, 1.723826288076145, 1.608975335941946, 1.468930418778976, 1.850919706609337, 1.6973601392634514, 1.5958352455077027, 1.4700194036212053, 1.7988711982144054, 1.6792336569678512, 1.6011629333731188, 1.5032627131200094]}\r\n","r = {2: [1.8962629124977626, 1.896480486783705, 1.896256178668206, 1.8959803400411601, 1.850202494981479, 1.8505385473472078, 1.8506694703450683, 1.850919706609337, 1.8005364250011835, 1.8001742035508146, 1.8007124482735408, 1.7988711982144054], 3: [1.7239882029844498, 1.7243868541167449, 1.7239275780422287, 1.723826288076145, 1.6973675066418445, 1.6972962666544136, 1.6976147903436911, 1.6973601392634514, 1.6773807149581863, 1.6775618514316089, 1.6782787464453222, 1.6792336569678512], 4: [1.6089779539576528, 1.6092665684873428, 1.6091976907844414, 1.608975335941946, 1.595436754372912, 1.5962447933024317, 1.5961544800750154, 1.5958352455077027, 1.60014852941341, 1.5986150593305195, 1.599383160456623, 1.6011629333731188], 8: [1.4681648514608552, 1.4682749740849188, 1.4679255368627417, 1.468930418778976, 1.4700986738837654, 1.4700810001217552, 1.472021334470938, 1.4700194036212053, 1.5025550599673736, 1.5039375399695205, 1.5026751528360311, 1.5032627131200094]}\r\n","us = []\r\n","lu = []\r\n","for i in r:\r\n","    u = []\r\n","    for j in r[i]:\r\n","        u.append(j)\r\n","    us.append(u)\r\n","    lu.append(i)\r\n","\r\n","\r\n","# Random test data\r\n","np.random.seed(19680801)\r\n","all_data = us\r\n","labels = lu\r\n","\r\n","fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\r\n","\r\n","# rectangular box plot\r\n","bplot1 = axes[0].boxplot(all_data,\r\n","                         vert=True,  # vertical box alignment\r\n","                         patch_artist=True,  # fill with color\r\n","                         labels=labels)  # will be used to label x-ticks\r\n","axes[0].set_title('Rectangular box plot')\r\n","\r\n","# notch shape box plot\r\n","bplot2 = axes[1].boxplot(all_data,\r\n","                         notch=True,  # notch shape\r\n","                         vert=True,  # vertical box alignment\r\n","                         patch_artist=True,  # fill with color\r\n","                         labels=labels)  # will be used to label x-ticks\r\n","axes[1].set_title('Notched box plot')\r\n","\r\n","# fill with colors\r\n","colors = ['pink', 'lightblue', 'lightgreen']\r\n","for bplot in (bplot1, bplot2):\r\n","    for patch, color in zip(bplot['boxes'], colors):\r\n","        patch.set_facecolor(color)\r\n","\r\n","# adding horizontal grid lines\r\n","for ax in axes:\r\n","    ax.yaxis.grid(True)\r\n","    ax.set_xlabel('Three separate samples')\r\n","    ax.set_ylabel('Observed values')\r\n","\r\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 648x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"xsM94b0Qu-Ts"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hrnAtKmJu-Wn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ybDVcDvHkJ6v","executionInfo":{"status":"error","timestamp":1611612297881,"user_tz":180,"elapsed":25115038,"user":{"displayName":"Pedro Henrique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBTPHdXq55BqU30ZQ23IGjf75MSq79U70jv4g-aw=s64","userId":"14617956053752650928"}},"outputId":"12d395e0-b488-4f34-d264-d06fd3554e5b"},"source":["start = time.time()\r\n","\r\n","all_users_predict, all_items_predict, users_items_array_to_predict = readFile(\"fold/targets-0.csv\", type=\"train\",\r\n","                                                                                  type_return=\"array\")\r\n","all_users_train, all_items_train, users_items_map_train = readFile(\"fold/ratings-0.csv\", type=\"train\")\r\n","\r\n","y_true = []\r\n","for i in range(len(users_items_array_to_predict)):\r\n","    y_true.append(users_items_array_to_predict[i][2])\r\n","y_true = np.array(y_true)\r\n","\r\n","\r\n","indexes_users, users_without_rating = indexTwoSets(all_users_train, all_users_predict)\r\n","indexes_items, _ = indexTwoSets(all_items_predict, all_items_train)\r\n","\r\n","end = time.time()\r\n","print(\"Elapsed Time To Read and Index: %.2fs\" % (end - start))\r\n","best_comb = 99999999999\r\n","bla = []\r\n","for num_latent_factor in [2, 5, 10, 24, 48]:\r\n","    for alpha in [0.1, 0.01, 0.001, 0.0001]:\r\n","        for lambda_reg in [0.01, 0.001, 0.0001, 0.0005]:\r\n","            for type_of_pred in [1, 2, 3]:\r\n","                t1 = time.time()\r\n","                model = SVD(num_iteracoes=20, num_latent_factor=num_latent_factor, alpha=alpha, lambda_reg=lambda_reg)\r\n","                # model = SVD(num_iteracoes=2, num_latent_factor=num_latent_factor, alpha=alpha)\r\n","                model.fit(users_items_map_train, indexes_users, indexes_items)\r\n","\r\n","                predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items)\r\n","                \r\n","                if type_of_pred == 1:\r\n","                    predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items, users_without_rating, type_of_predict_for_users_without_rating='mean_item')\r\n","                elif type_of_pred == 2:\r\n","                    predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items, users_without_rating, type_of_predict_for_users_without_rating='global_mean')\r\n","                else:\r\n","                    predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items)\r\n","\r\n","                predicts = np.array(predicts)\r\n","                rmse = np.nan_to_num(np.sqrt(np.mean((y_true - predicts) ** 2)))\r\n","                if rmse == 0:\r\n","                    rmse = 99999999999\r\n","                t2 = time.time()\r\n","                t3 = t2 - t1\r\n","                print(\"---------------------------\")\r\n","                print(f\"alpha: {alpha} ---- latentf: {num_latent_factor} ---- time: {t3}s\")\r\n","                print(f\"rmse: {rmse}\")\r\n","                if rmse < best_comb:\r\n","                    best_comb = rmse\r\n","                    bla = []\r\n","                    bla.append(num_latent_factor)\r\n","                    bla.append(alpha)\r\n","                    bla.append(lambda_reg)\r\n","                    bla.append(type_of_pred)\r\n","print(\"--------FINAL------\")\r\n","print(best_comb)\r\n","print(bla)\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Elapsed Time To Read and Index: 1.11s\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:364: RuntimeWarning: overflow encountered in multiply\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:348: RuntimeWarning: overflow encountered in multiply\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:364: RuntimeWarning: invalid value encountered in subtract\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:402: RuntimeWarning: overflow encountered in matmul\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:160: RuntimeWarning: overflow encountered in reduce\n","  ret = umr_sum(arr, axis, dtype, out, keepdims)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:160: RuntimeWarning: invalid value encountered in reduce\n","  ret = umr_sum(arr, axis, dtype, out, keepdims)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in square\n"],"name":"stderr"},{"output_type":"stream","text":["---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 3.764319658279419s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 3.7064437866210938s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 4.115528345108032s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 3.727811574935913s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 3.605473279953003s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 3.6094021797180176s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 3.6291263103485107s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 3.581017017364502s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 3.596412420272827s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 3.6075613498687744s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 3.5984511375427246s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 2 ---- time: 3.5773067474365234s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 189.29610967636108s\n","rmse: 1.738794705920452\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 193.6654806137085s\n","rmse: 1.7734548962103378\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 189.80331540107727s\n","rmse: 1.8456696989874504\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 190.3719654083252s\n","rmse: 1.7536407698028067\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 194.08745050430298s\n","rmse: 1.7893727165478905\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 188.73596811294556s\n","rmse: 1.8452487404575972\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 192.10769939422607s\n","rmse: 1.7554215382661051\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 192.21138834953308s\n","rmse: 1.7912902778906319\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 192.03664660453796s\n","rmse: 1.8453451502425144\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 190.17458367347717s\n","rmse: 1.7546223032059074\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 191.60992407798767s\n","rmse: 1.7904294601255637\n","---------------------------\n","alpha: 0.01 ---- latentf: 2 ---- time: 190.95426201820374s\n","rmse: 1.8452983298085193\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 188.9829580783844s\n","rmse: 1.8080656224167724\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 191.78194522857666s\n","rmse: 1.9734714211300162\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 190.3734266757965s\n","rmse: 1.9034375392325658\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 189.53627467155457s\n","rmse: 1.8093263155772237\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 192.82616448402405s\n","rmse: 1.975211209724951\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 189.9564073085785s\n","rmse: 1.902886964977007\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 187.46824145317078s\n","rmse: 1.8094697338700216\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 189.92961192131042s\n","rmse: 1.9754021494755032\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 193.16469979286194s\n","rmse: 1.902843593857942\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 189.48807072639465s\n","rmse: 1.8094055955555668\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 189.12981057167053s\n","rmse: 1.9753168994948\n","---------------------------\n","alpha: 0.001 ---- latentf: 2 ---- time: 191.98247170448303s\n","rmse: 1.902862602404025\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 190.2795431613922s\n","rmse: 2.625534527397168\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 189.15322995185852s\n","rmse: 2.809757874565816\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 191.98820209503174s\n","rmse: 2.6501717049584097\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 188.8595154285431s\n","rmse: 2.6238308787540574\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 192.01881790161133s\n","rmse: 2.8086855778906723\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 189.54825735092163s\n","rmse: 2.648347408612129\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 190.3204562664032s\n","rmse: 2.6236701475437187\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 189.08566284179688s\n","rmse: 2.8085873030188964\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 189.59055995941162s\n","rmse: 2.64817424832868\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 190.9956135749817s\n","rmse: 2.623741366066217\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 187.79157710075378s\n","rmse: 2.8086307785938915\n","---------------------------\n","alpha: 0.0001 ---- latentf: 2 ---- time: 190.66258835792542s\n","rmse: 2.6482509991114163\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:356: RuntimeWarning: overflow encountered in multiply\n"],"name":"stderr"},{"output_type":"stream","text":["---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.654010772705078s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.617905378341675s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.616089105606079s\n","rmse: 1.7976931348623157e+308\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:356: RuntimeWarning: invalid value encountered in add\n"],"name":"stderr"},{"output_type":"stream","text":["---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.6397476196289062s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.6319503784179688s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.6719911098480225s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.6395633220672607s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.6344738006591797s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.651766777038574s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.6351318359375s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.625436782836914s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 5 ---- time: 3.6208176612854004s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 193.09788846969604s\n","rmse: 1.6303239687522795\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 188.8426547050476s\n","rmse: 1.6593294388577988\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 190.2949116230011s\n","rmse: 1.6350868672722283\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 192.19967126846313s\n","rmse: 1.6365529985034215\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 188.66702485084534s\n","rmse: 1.6658242910891923\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 191.14275860786438s\n","rmse: 1.638987543187858\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 191.0006709098816s\n","rmse: 1.637276348763777\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 192.64279103279114s\n","rmse: 1.6665808083967675\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 193.07237601280212s\n","rmse: 1.6394965532638737\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 193.26068210601807s\n","rmse: 1.6369523611015029\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 191.19625401496887s\n","rmse: 1.666241914943672\n","---------------------------\n","alpha: 0.01 ---- latentf: 5 ---- time: 188.9717104434967s\n","rmse: 1.63926728404951\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 191.91395568847656s\n","rmse: 1.5231070815942376\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 193.0450963973999s\n","rmse: 1.591315939799424\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 189.63991689682007s\n","rmse: 1.5376986865790319\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 192.16452407836914s\n","rmse: 1.5232767429712868\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 191.80947637557983s\n","rmse: 1.5914887465639054\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 190.58021187782288s\n","rmse: 1.5374402814919474\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 196.23056530952454s\n","rmse: 1.5233061657190512\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 193.65104007720947s\n","rmse: 1.5915176253156995\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 191.8833770751953s\n","rmse: 1.537426166214776\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 189.63204097747803s\n","rmse: 1.523292808719818\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 193.09449887275696s\n","rmse: 1.5915045294979289\n","---------------------------\n","alpha: 0.001 ---- latentf: 5 ---- time: 190.67138481140137s\n","rmse: 1.537432175785892\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 193.6120913028717s\n","rmse: 1.6904527096006543\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 192.06708693504333s\n","rmse: 1.7774890715517435\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 190.37130165100098s\n","rmse: 1.6962432703247574\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 193.48595905303955s\n","rmse: 1.6894487266499307\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 194.8223385810852s\n","rmse: 1.7767419366391337\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 191.04434847831726s\n","rmse: 1.6952064076040332\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 192.76468682289124s\n","rmse: 1.6893583785326145\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 192.46157312393188s\n","rmse: 1.776676499036891\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 193.026513338089s\n","rmse: 1.6951126523841131\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 191.15978264808655s\n","rmse: 1.6893983071950276\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 190.01264142990112s\n","rmse: 1.7767053738301997\n","---------------------------\n","alpha: 0.0001 ---- latentf: 5 ---- time: 192.5103840827942s\n","rmse: 1.6951540979895239\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.877962827682495s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.809938669204712s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.86270809173584s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.8259243965148926s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.8057472705841064s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.8106300830841064s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.8132998943328857s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.8193111419677734s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.811490535736084s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.8343276977539062s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.8064780235290527s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 10 ---- time: 3.801687002182007s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 192.03066778182983s\n","rmse: 1.6221853541977946\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 194.3454465866089s\n","rmse: 1.6396424407472299\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 191.64555382728577s\n","rmse: 1.6467200165328633\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 190.26882457733154s\n","rmse: 1.6227472953739486\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 191.01381635665894s\n","rmse: 1.640127070380782\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 193.256582736969s\n","rmse: 1.6505163488703254\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 189.53223705291748s\n","rmse: 1.6228290893246637\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 190.9702570438385s\n","rmse: 1.6402006373847708\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 196.1373109817505s\n","rmse: 1.6509500307075518\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 190.60636043548584s\n","rmse: 1.6227921250330102\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 189.94956302642822s\n","rmse: 1.6401673419083944\n","---------------------------\n","alpha: 0.01 ---- latentf: 10 ---- time: 192.54971837997437s\n","rmse: 1.6507559826454825\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 191.2241051197052s\n","rmse: 1.533845770996123\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 191.63279724121094s\n","rmse: 1.5549784122816361\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 194.01752924919128s\n","rmse: 1.535947331878896\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 192.61433172225952s\n","rmse: 1.532891714630329\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 189.95134091377258s\n","rmse: 1.5542531574619516\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 195.17468523979187s\n","rmse: 1.5351591797007629\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 190.03839945793152s\n","rmse: 1.5328072085098998\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 192.06943368911743s\n","rmse: 1.5541911373244854\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 190.88646268844604s\n","rmse: 1.5350911560522482\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 193.15701532363892s\n","rmse: 1.532844521937909\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 194.0280818939209s\n","rmse: 1.554218465893821\n","---------------------------\n","alpha: 0.001 ---- latentf: 10 ---- time: 192.45558524131775s\n","rmse: 1.5351211463739285\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 193.5162491798401s\n","rmse: 1.6830643419174383\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 195.4876983165741s\n","rmse: 1.7168104356051388\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 190.066645860672s\n","rmse: 1.684282881862326\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 194.02388501167297s\n","rmse: 1.6838232128306676\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 190.11748361587524s\n","rmse: 1.7177084697194487\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 191.37959957122803s\n","rmse: 1.6850852689602902\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 192.66837239265442s\n","rmse: 1.6839075823543295\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 193.5859363079071s\n","rmse: 1.7178063245779038\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 190.74954509735107s\n","rmse: 1.6851739479971801\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 192.6004343032837s\n","rmse: 1.68386989435361\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 190.71211743354797s\n","rmse: 1.7177626527875722\n","---------------------------\n","alpha: 0.0001 ---- latentf: 10 ---- time: 189.98696613311768s\n","rmse: 1.6851343456073173\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.815619707107544s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.771630525588989s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.802914381027222s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.762277364730835s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.7363691329956055s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.808088302612305s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.77967381477356s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.765777349472046s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.754523038864136s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.74262547492981s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.736304521560669s\n","rmse: 99999999999\n","---------------------------\n","alpha: 0.1 ---- latentf: 24 ---- time: 4.785279273986816s\n","rmse: 1.7976931348623157e+308\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 197.76308465003967s\n","rmse: 2.125828253750559\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 194.9146671295166s\n","rmse: 2.1362450498986023\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 195.2704634666443s\n","rmse: 2.3178071637926987\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 196.26804780960083s\n","rmse: 2.1299951926059877\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 194.09195613861084s\n","rmse: 2.1410169205335867\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 194.07079195976257s\n","rmse: 2.3198456661915365\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 196.77770471572876s\n","rmse: 2.130425184917957\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 195.86394619941711s\n","rmse: 2.14150791971087\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 194.1279809474945s\n","rmse: 2.3200536323473706\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 196.20683765411377s\n","rmse: 2.1302337767381245\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 192.27849864959717s\n","rmse: 2.1412893858617545\n","---------------------------\n","alpha: 0.01 ---- latentf: 24 ---- time: 193.14546251296997s\n","rmse: 2.319961111888816\n","---------------------------\n","alpha: 0.001 ---- latentf: 24 ---- time: 193.82885241508484s\n","rmse: 2.478090083563528\n","---------------------------\n","alpha: 0.001 ---- latentf: 24 ---- time: 195.1483383178711s\n","rmse: 2.8805996589786407\n","---------------------------\n","alpha: 0.001 ---- latentf: 24 ---- time: 194.64573860168457s\n","rmse: 2.5449534019186504\n","---------------------------\n","alpha: 0.001 ---- latentf: 24 ---- time: 192.866055727005s\n","rmse: 2.4778547358123144\n","---------------------------\n","alpha: 0.001 ---- latentf: 24 ---- time: 195.30178093910217s\n","rmse: 2.881912946732529\n","---------------------------\n","alpha: 0.001 ---- latentf: 24 ---- time: 196.1791398525238s\n","rmse: 2.5444254867439002\n","---------------------------\n","alpha: 0.001 ---- latentf: 24 ---- time: 192.59686923027039s\n","rmse: 2.4778387195073623\n","---------------------------\n","alpha: 0.001 ---- latentf: 24 ---- time: 196.38538527488708s\n","rmse: 2.8820508125919537\n","---------------------------\n","alpha: 0.001 ---- latentf: 24 ---- time: 193.10932064056396s\n","rmse: 2.544379516622585\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-9ad4a7977afb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iteracoes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_latent_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_latent_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;31m# model = SVD(num_iteracoes=2, num_latent_factor=num_latent_factor, alpha=alpha)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_items_map_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_items_array_to_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-f8c967e21ac5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, users_items_map_train, indexes_users, indexes_items)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                                                            indexes_items[\n\u001b[1;32m    355\u001b[0m                                                                                i]] - 2 * self.alpha * self.lambda_reg * \\\n\u001b[0;32m--> 356\u001b[0;31m                          self.P[indexes_users[u]] - 2 * self.alpha * self.lambda_reg * self.Q[:,\n\u001b[0m\u001b[1;32m    357\u001b[0m                                                                                        indexes_items[\n\u001b[1;32m    358\u001b[0m                                                                                            i]]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"BnRqKtk_EA7H"},"source":["start = time.time()\r\n","\r\n","all_users_predict, all_items_predict, users_items_array_to_predict = readFile(\"fold/targets-2.csv\", type=\"train\",\r\n","                                                                                  type_return=\"array\")\r\n","all_users_train, all_items_train, users_items_map_train = readFile(\"fold/ratings-2.csv\", type=\"train\")\r\n","\r\n","y_true = []\r\n","for i in range(len(users_items_array_to_predict)):\r\n","    y_true.append(users_items_array_to_predict[i][2])\r\n","y_true = np.array(y_true)\r\n","\r\n","\r\n","indexes_users, users_without_rating = indexTwoSets(all_users_train, all_users_predict)\r\n","indexes_items, _ = indexTwoSets(all_items_predict, all_items_train)\r\n","\r\n","end = time.time()\r\n","print(\"Elapsed Time To Read and Index: %.2fs\" % (end - start))\r\n","best_comb = 99999999999\r\n","bla = []\r\n","for num_latent_factor in [2, 5, 10, 24, 48]:\r\n","    for alpha in [0.1, 0.01, 0.001, 0.0001]:\r\n","        for lambda_reg in [0.01, 0.001, 0.0001, 0.0005]:\r\n","            for type_of_pred in [1, 2, 3]:\r\n","                t1 = time.time()\r\n","                model = SVD(num_iteracoes=20, num_latent_factor=num_latent_factor, alpha=alpha, lambda_reg=lambda_reg)\r\n","                # model = SVD(num_iteracoes=2, num_latent_factor=num_latent_factor, alpha=alpha)\r\n","                model.fit(users_items_map_train, indexes_users, indexes_items)\r\n","\r\n","                predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items)\r\n","                \r\n","                if type_of_pred == 1:\r\n","                    predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items, users_without_rating, type_of_predict_for_users_without_rating='mean_item')\r\n","                elif type_of_pred == 2:\r\n","                    predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items, users_without_rating, type_of_predict_for_users_without_rating='global_mean')\r\n","                else:\r\n","                    predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items)\r\n","\r\n","                predicts = np.array(predicts)\r\n","                rmse = np.nan_to_num(np.sqrt(np.mean((y_true - predicts) ** 2)))\r\n","                if rmse == 0:\r\n","                    rmse = 99999999999\r\n","                t2 = time.time()\r\n","                t3 = t2 - t1\r\n","                print(\"---------------------------\")\r\n","                print(f\"alpha: {alpha} ---- latentf: {num_latent_factor} ---- time: {t3}s\")\r\n","                print(f\"rmse: {rmse}\")\r\n","                if rmse < best_comb:\r\n","                    best_comb = rmse\r\n","                    bla = []\r\n","                    bla.append(num_latent_factor)\r\n","                    bla.append(alpha)\r\n","                    bla.append(lambda_reg)\r\n","                    bla.append(type_of_pred)\r\n","print(\"--------FINAL------\")\r\n","print(best_comb)\r\n","print(bla)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXQSaR96EBV6"},"source":["start = time.time()\r\n","\r\n","all_users_predict, all_items_predict, users_items_array_to_predict = readFile(\"fold/targets-1.csv\", type=\"train\",\r\n","                                                                                  type_return=\"array\")\r\n","all_users_train, all_items_train, users_items_map_train = readFile(\"fold/ratings-1.csv\", type=\"train\")\r\n","\r\n","y_true = []\r\n","for i in range(len(users_items_array_to_predict)):\r\n","    y_true.append(users_items_array_to_predict[i][2])\r\n","y_true = np.array(y_true)\r\n","\r\n","\r\n","indexes_users, users_without_rating = indexTwoSets(all_users_train, all_users_predict)\r\n","indexes_items, _ = indexTwoSets(all_items_predict, all_items_train)\r\n","\r\n","end = time.time()\r\n","print(\"Elapsed Time To Read and Index: %.2fs\" % (end - start))\r\n","best_comb = 99999999999\r\n","bla = []\r\n","for num_latent_factor in [2, 5, 10, 24, 48]:\r\n","    for alpha in [0.1, 0.01, 0.001, 0.0001]:\r\n","        for lambda_reg in [0.01, 0.001, 0.0001, 0.0005]:\r\n","            for type_of_pred in [1, 2, 3]:\r\n","                t1 = time.time()\r\n","                model = SVD(num_iteracoes=20, num_latent_factor=num_latent_factor, alpha=alpha, lambda_reg=lambda_reg)\r\n","                # model = SVD(num_iteracoes=2, num_latent_factor=num_latent_factor, alpha=alpha)\r\n","                model.fit(users_items_map_train, indexes_users, indexes_items)\r\n","\r\n","                predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items)\r\n","                \r\n","                if type_of_pred == 1:\r\n","                    predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items, users_without_rating, type_of_predict_for_users_without_rating='mean_item')\r\n","                elif type_of_pred == 2:\r\n","                    predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items, users_without_rating, type_of_predict_for_users_without_rating='global_mean')\r\n","                else:\r\n","                    predicts = model.predict(users_items_array_to_predict, indexes_users, indexes_items)\r\n","\r\n","                predicts = np.array(predicts)\r\n","                rmse = np.nan_to_num(np.sqrt(np.mean((y_true - predicts) ** 2)))\r\n","                if rmse == 0:\r\n","                    rmse = 99999999999\r\n","                t2 = time.time()\r\n","                t3 = t2 - t1\r\n","                print(\"---------------------------\")\r\n","                print(f\"alpha: {alpha} ---- latentf: {num_latent_factor} ---- time: {t3}s\")\r\n","                print(f\"rmse: {rmse}\")\r\n","                if rmse < best_comb:\r\n","                    best_comb = rmse\r\n","                    bla = []\r\n","                    bla.append(num_latent_factor)\r\n","                    bla.append(alpha)\r\n","                    bla.append(lambda_reg)\r\n","                    bla.append(type_of_pred)\r\n","print(\"--------FINAL------\")\r\n","print(best_comb)\r\n","print(bla)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcldpE1HEBYg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"51-gJFh4EBbJ"},"source":[""],"execution_count":null,"outputs":[]}]}